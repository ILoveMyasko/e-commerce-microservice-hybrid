\chapter{Реализация программного комплекса и методика проведения эксперимента}

\section{Программная реализация ключевых механизмов}
В ходе разработки особое внимание было уделено реализации механизмов, влияющих на производительность сетевого взаимодействия.
\subsection{Реализация пула каналов (Channel Pooling)}
Стандартная реализация gRPC-клиента использует один HTTP/2 канал для всех запросов. В ходе предварительных тестов было выявлено, что при высокой конкурентной нагрузке это приводит к исчерпанию лимита одновременных стримов (Max Concurrent Streams) и блокировкам.
Для решения этой проблемы на стороне API Gateway был программно реализован механизм пула каналов. При инициализации приложения создается фиксированный набор управляемых каналов (ManagedChannel), и для каждого исходящего запроса используется алгоритм балансировки Round Robin. Это позволяет параллелизировать обработку запросов на транспортном уровне.
\subsection{Реализация пакетной обработки (Batching)}
В сервисе складского учета реализован метод, принимающий список идентификаторов товаров. На уровне доступа к данным это трансформируется в единый SQL-запрос с оператором IN, что исключает проблему «N+1» запросов как на уровне сети, так и на уровне базы данных.
\section{Стенд для проведения экспериментов}
Для обеспечения чистоты эксперимента и исключения влияния внешних факторов (интернет-провайдеры, облачные балансировщики) тестирование проводилось в изолированной локальной среде.

Аппаратная конфигурация стенда:
\begin{itemize}
	\item Процессор: Ryzen 7 7700 8-core
	\item Оперативная память: 32 ГБ.
	\item Операционная система: Windows 11.
\end{itemize}
Все микросервисы были запущены в виде локальных Java-процессов с выделением достаточного объема Heap Memory (4 ГБ на процесс) для предотвращения пауз сборщика мусора (GC Stop-the-World) во время замеров.
\section{Инструментарий тестирования}
Для проведения нагрузочного тестирования и эмуляции сетевых условий использовались следующие инструменты:
\begin{enumerate}
	\item Grafana k6: Инструмент для нагрузочного тестирования с открытым исходным кодом. Использовался для генерации виртуальных пользователей (Virtual Users), отправки GraphQL-запросов и сбора метрик задержки (Latency) и пропускной способности (RPS).
	\item Toxiproxy: прокси-сервер для симуляции сетевых условий. Использовался для искусственного ограничения пропускной способности канала (Bandwidth) и добавления сетевых задержек (Latency) между API Gateway и микросервисами. Это позволило приблизить условия локального теста к реалиям распределенных облачных систем и мобильных сетей, а также симулировать ограничения пропускной способности каналов.
\end{enumerate}
\section{Генерация тестовых данных}
Критическим фактором для сравнения эффективности протоколов является структура и объем передаваемых данных. Для экспериментов был разработан модуль генерации синтетических данных, создающий базу из 1000 товаров со следующими характеристиками:
\begin{itemize}
	\item \textit{Текстовые данные:} каждому товару присваивалось текстовое описание, объем которого варьировался в зависимости от сценария тестирования. Это необходимо для проверки эффективности обработки строк в JSON и Protobuf.
	\item \textit{Числовые данные:} для каждого товара генерировался массив, выступающий в роли данных об истории цен, размер которого также зависел от теста. Данный тип данных выбран для демонстрации эффективности механизма packed encoding в Protobuf по сравнению с текстовой записью массивов в JSON.
\end{itemize}
\section{Методика и сценарии тестирования}
Тестирование проводилось в два этапа: оценка накладных расходов на сериализацию (идеальная сеть) и оценка влияния пропускной способности (ограниченная сеть). Для всех тестов использовалась нагрузка в 20 одновременных виртуальных пользователей (Virtual Users), каждый из которых генерировал 1 запрос в секунду. Для gRPC-клиента был сконфигурирован пул из 20 каналов, чтобы исключить влияние блокировок HTTP/2 и тестировать эффективность протокола в чистом виде. Сравнительный анализ производительности REST и gRPC проводился в рамках трех сценариев. В качестве метрик были выбраны показатели времени ответа: среднее время(avg), 95-й процентиль (p95)
\subsection{Сценарий 1: Статический анализ объема данных}
Цель: измерить «чистый» размер полезной нагрузки (payload) без учета заголовков.

Методика: один и тот же набор из 1000 объектов сериализуется в JSON (библиотека Jackson) и в Protobuf. Производится сравнение размера полученных байт-массивов.
\subsection{Сценарий 2: Тестирование в идеальных условиях}
Цель: оценить накладные расходы на сериализацию и десериализацию данных.

Условия: отсутствие типичных сетевых ограничений.
\subsection{Сценарий 3: Эмуляция ограниченной сети (Network Constrained)}
Цель: сравнить время отклика системы в условиях, приближенных к мобильным сетям (3G/4G) или перегруженным каналам связи.

Условия: с помощью Toxiproxy устанавливается ограничение пропускной способности (Bandwidth) на уровне 200 КБ/с на каждое соединение.

Нагрузка: 20 одновременных пользователей.


\section{Результаты нагрузочного тестирования и анализ данных}
В данном разделе представлены количественные результаты экспериментов, проведенных согласно методике, описанной выше. 

\subsection{Этап 1: Тестирование в условиях идеальной сети (Localhost)}
Цель этапа — оценить накладные расходы на сериализацию (CPU Overhead).
Сетевые задержки и типовые ограничения пропускной способности отсутствуют, поскольку все сервисы запущены на одном хосте.

\textbf{Сценарий 1:} Передача преимущественно текстовых данных («тяжелое» описание товара весом в 3 КБ, история цен минимальна — 5 записей). Общий объем ответа около 3 МБ.

\textbf{Сценарий 2:} Увеличение объема числовых данных (история цен — 100 записей на товар). Текстовое описание сохранено.
\begin{table}[htbp!]
	\centering
	\caption{Результаты тестирования без сетевых ограничений (Latency в мс)}
	\begin{tabular}{|l|c|c|c|c|}
		\hline
		\textbf{Метрика} & \textbf{REST (Сцен. 1)} & \textbf{gRPC (Сцен. 1)} & \textbf{REST (Сцен. 2)} & \textbf{gRPC (Сцен. 2)} \\ \hline
		Avg & 90.46 & 79.16 & 168.16 & 154.33 \\ \hline
		Med & 91.54 & 74.58 & 150.71 & 147.17 \\ \hline
		p95 & 110.59 & 94.89 & 221.05 & 211.12 \\ \hline
	\end{tabular}
\end{table}
\textbf{Анализ:}
В условиях отсутствия сетевых задержек (Localhost) оба протокола демонстрируют сопоставимую производительность. gRPC показывает незначительное преимущество (на 10-12\% быстрее) по среднему времени отклика. Это опровергает гипотезу о том, что бинарная сериализация в Java значительно медленнее JSON-процессинга на современных JVM. Однако разница в абсолютных величинах (10-15 мс) не является критической для пользователя, что подтверждает вывод: в локальной сети выбор протокола слабо влияет на Latency.
\subsection{Этап 2: Тестирование в условиях ограниченной сети (Toxiproxy)}
Цель этапа — оценить влияние размера полезной нагрузки (Payload) на время отклика.
С помощью Toxiproxy введена искусственная задержка пропускной способности (Bandwidth Throttling), имитирующая перегруженные каналы связи или мобильные сети.

\textbf{Сценарий 3 (Текстовая доминация):}
\begin{itemize}
	\item Данные: Описание товара 1.2 КБ, История цен — 5 чисел.
	\item Сеть: 1000 КБ/с на канал (имитация хорошего 3G / слабого 4G).
\end{itemize}

\textbf{Сценарий 4 (Числовая доминация):}
\begin{itemize}
	\item Данные: Описание товара 0.3 КБ, История цен — 100 чисел. (Суммарно 0.3 МБ текста на запрос + массив чисел).
	\item Сеть: 200 КБ/с на канал (имитация перегруженной сети / EDGE).
\end{itemize}
\begin{table}[htbp!]
	\centering
	\caption{Результаты тестирования с ограничением сети (Latency в секундах)}
	\begin{tabular}{|l|c|c|c|c|}
		\hline
		\textbf{Метрика} & \textbf{REST (Сцен. 3)} & \textbf{gRPC (Сцен. 3)} & \textbf{REST (Сцен. 4)} & \textbf{gRPC (Сцен. 4)} \\ \hline
		Avg & 6.65 & 6.33 & 4.56 & \textbf{2.83} \\ \hline
		p95 & 6.65 & 6.34 & 4.58 & \textbf{2.87} \\ \hline
	\end{tabular}
\end{table}
\textbf{Анализ:}
\begin{enumerate}
	\item \textit{Влияние типа данных (Текст):} В Сценарии 3, где преобладают текстовые данные, разница между протоколами минимальна. Это объясняется тем, что строки в формате JSON и Protobuf кодируются одинаково (UTF-8). Накладные расходы JSON (кавычки, скобки) на фоне длинного текста составляют незначительную долю объема.
	\item \textit{Влияние типа данных (Числа):} В Сценарии 4, характерном для аналитических блоков E-commerce (история цен, остатки, метрики), gRPC демонстрирует существенное преимущество. Среднее время отклика сократилось с 4.56 с до 2.83 с (ускорение в 1.6 раза).
\end{enumerate}
Причина такого разрыва заключается в эффективности кодирования числовых массивов. В JSON массив из 100 чисел кодируется текстом (каждая цифра — байт + разделители), занимая около 400-600 байт. В Protobuf используется механизм \texttt{packed encoding} и алгоритм Varint, который сжимает этот же массив до 150-200 байт.
\subsection{Итоговый вывод по эксперименту}
Результаты экспериментов подтверждают, что эффективность гибридной архитектуры (gRPC во внутреннем контуре) напрямую зависит от структуры передаваемых данных:
\begin{itemize}
	\item Для передачи преимущественно текстового контента (описания, блоги) выигрыш от перехода на gRPC минимален и может не оправдывать усложнение инфраструктуры.
	\item Для передачи структурированных данных, содержащих большое количество числовых полей и массивов (что типично для каталогов, складского учета и аналитики E-commerce), использование gRPC позволяет сократить сетевые задержки на 30-40\% в условиях ограниченной пропускной способности сети.
\end{itemize}
\section{Вывод к главе 3}
Разработанная методика эксперимента позволяет всесторонне оценить эффективность предложенной архитектуры. Использование синтетических «тяжелых» данных дает возможность выявить преимущества бинарной сериализации, а применение эмулятора сети Toxiproxy позволяет выйти за рамки синтетических локальных тестов и смоделировать поведение системы в реальных условиях эксплуатации, где пропускная способность сети является ограниченным ресурсом.